{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the trajectory of perceptrons and expert systems, I believe that deep neural networks have a promising future. In comparison, neural networks have a stronger foundation based on statistical methods and large amounts of data which allow them to tackle complex, not black-and-white situations. Perceptrons and expert systems have been looked down upon because they had very little prospect in solving real-world problems.\n",
    "\n",
    "Neural networks are capable of solving problems efficiently and quickly. Even when neural networks give partial or less-accurate solutions, those solutions are often still extremely. At work, I’m currently working with Uber’s open source, Ludwig, and it is able to solve real-world problems. For example, it is used to perform Machine Language translations, categorize  (positive/negative) emotions in language, as well as classify and caption images. \n",
    "\n",
    "But despite all of the progress and promise neural nets have lend to AI, it’s important to not exxagerate neural networks’ ability. I do not believe that nueral networks will be able to transcend humanity or be able to truly learn and discern like humans. In fact, I believe that neural networks are dependent on humans. A neural network depends on humans to define its goals (even in unsupervised learning- the goals are often driven by the data or are simple goals)  and to feed it data. Therefore, neural networks, I believe can develop to become even more efficient,  faster, and more accurate in not only producing solutions but also handling larger volumes of data. But it won’t be able to transcend human cognition and will eventually meet its limitations. \n",
    "\n",
    "Sources: \n",
    "\n",
    "https://towardsdatascience.com/limitations-of-deep-learning-in-ai-research-5eed166a4205  \n",
    "https://arxiv.org/ftp/arxiv/papers/1801/1801.00631.pdf (p. 5-10) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is submitted as an image within the Homework 4 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is heavily inspired by kvlinden's keras-cnn example\n",
    "\n",
    "# import essential libraries and fashion_mnist dataset\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "#  3 layer convnet using conv2d and MaxPool\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image count: 60000\n",
      "train_image shape: (60000, 28, 28)\n",
      "train_image type: uint8\n",
      "train_labels type: uint8\n",
      "\n",
      "test_image count: 10000\n",
      "test_image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "#Describe the training and testing set:\n",
    "\n",
    "print('train_image count:', len(train_images))\n",
    "print('train_image shape:', train_images.shape)\n",
    "print('train_image type:', train_images.dtype)\n",
    "print('train_labels type:', train_labels.dtype)\n",
    "\n",
    "print('\\ntest_image count:', len(test_images))\n",
    "print('test_image shape:', test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ss63/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.5243 - acc: 0.8052\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.3239 - acc: 0.8822\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 31s 525us/step - loss: 0.2783 - acc: 0.8987\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 31s 523us/step - loss: 0.2472 - acc: 0.9089\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 31s 522us/step - loss: 0.2244 - acc: 0.9178\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.2057 - acc: 0.9248\n",
      "10000/10000 [==============================] - 2s 193us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26510446031689644, 0.9042]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=6, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network, of 3 layers, gives me an accuracy of 90.42%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
